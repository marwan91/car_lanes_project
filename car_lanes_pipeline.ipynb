{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████▊| 221/222 [00:08<00:00, 24.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "Wall time: 9.97 s\n",
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████▉| 681/682 [00:25<00:00, 26.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.misc\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "def grayscale(img):\n",
    "    \n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "   \n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "   \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "   \n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    " \n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def average_line(myimage):\n",
    "    \n",
    "    myimage2 = grayscale(myimage)\n",
    "    lt=140;\n",
    "    ht=200;\n",
    "    vertix_points = np.array([ [(0,540),(400,320),(560,320),(960,540)]], dtype=np.int32)\n",
    "\n",
    "    myimage2=gaussian_blur(myimage2,3)\n",
    "    canny_image=canny(myimage2,lt,ht)\n",
    "    masked_image = region_of_interest(canny_image,vertix_points)\n",
    "\n",
    "\n",
    "    rho = 1 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 9     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_len = 25 #minimum number of pixels making up a line\n",
    "    max_line_gap = 30 \n",
    "\n",
    "    img_hough = hough_lines(masked_image, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "    \n",
    "    line_img=np.zeros_like(myimage) \n",
    "    \n",
    "    a_left= np.array([])\n",
    "    b_left= np.array([])\n",
    "    a_right= np.array([])\n",
    "    b_right= np.array([])\n",
    "   \n",
    "    my_lines = cv2.HoughLinesP(masked_image, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    for line in my_lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if(0.8>((y2-y1)/(x2-x1))>0.4 and x1>480):\n",
    "                a_right=np.append(a_right, np.polyfit([x1,x2],[y1,y2],1)[0])\n",
    "                b_right=np.append(b_right, np.polyfit([x1,x2],[y1,y2],1)[1])\n",
    "            elif(-0.8<((y2-y1)/(x2-x1))<-0.4 and x1<480):\n",
    "                a_left=np.append(a_left, np.polyfit([x1,x2],[y1,y2],1)[0])\n",
    "                b_left=np.append(b_left, np.polyfit([x1,x2],[y1,y2],1)[1])\n",
    "    a_right_avg=np.mean(a_right)\n",
    "    b_right_avg=np.mean(b_right)\n",
    "    a_left_avg=np.mean(a_left)\n",
    "    b_left_avg=np.mean(b_left)\n",
    "    \n",
    "    x1_right=int((540-b_right_avg)/a_right_avg)\n",
    "    x2_right=int((320-b_right_avg)/a_right_avg)\n",
    "    x1_left=int((540-b_left_avg)/a_left_avg)\n",
    "    x2_left=int((320-b_left_avg)/a_left_avg)\n",
    "     \n",
    "    cv2.line(line_img, (x1_right,540), (x2_right,320),[255, 0, 0], 8)\n",
    "    cv2.line(line_img, (x1_left,540), (x2_left,320),[255, 0, 0],8)\n",
    "    \n",
    "    \n",
    "    return line_img\n",
    "\n",
    "\n",
    "test_images = os.listdir(\"test_images/\")\n",
    "\n",
    "def process_image(image):\n",
    "   \n",
    "    top_img = average_line(image)\n",
    "    final_image = weighted_img(top_img,image, α=0.8, β=1., λ=0.)\n",
    "    return final_image\n",
    "\n",
    "# TODO: Build your pipeline that will draw lane lines on the test_images\n",
    "\n",
    "myimage = mpimg.imread('test_images/whiteCarLaneSwitch.jpg')\n",
    "\n",
    "for test_image in test_images:\n",
    "    out_image = mpimg.imread(\"test_images/{}\".format(test_image))\n",
    "    plt.imsave(\"test_images_output/{}\".format(test_image), process_image(out_image))\n",
    "\n",
    "#########################################\n",
    "\n",
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "##clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4').subclip(0,5)\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
